{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prediction_for_validation_set.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jtj7387/AI_Capstone/blob/main/prediction_for_validation_set.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CREjM2e-4YxQ"
      },
      "source": [
        "### 학습 완료 후 제대로 학습됐는지 테스트 해보기 위한 코드 (학습용 데이터 셋 중 남겨둔 일부로 테스트 해봄)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVXWXjmijFt3"
      },
      "source": [
        "img_rows, img_cols = 256, 256 # 이미지 크기\n",
        "channel = 3 # 채널 개수\n",
        "num_classes = 313 # 색상 양자화한 수\n",
        "kernel = 3\n",
        "epsilon = 1e-8\n",
        "nb_neighbors = 5\n",
        "# temperature parameter T\n",
        "T = 0.38"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0MQX4aGjUzs",
        "outputId": "c15728d7-6801-4fc9-f160-7b45ab6336bd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFpkMr43oxmy"
      },
      "source": [
        "# 노트북 파일이 위치한 폴더명 입력\n",
        "base_dir = '/content/drive/My Drive/2021_Spring_Capstone/'\n",
        "# 학습용 데이터가 위치한 폴더명 입력 (학습용 데이터 셋 중 학습에 사용하지 않고 남겨둔 사진들로 테스트하므로)\n",
        "img_dir = '/content/drive/My Drive/2021_Spring_Capstone/test_img'\n",
        "\n",
        "# pts_in_hull.npy 파일이 위치한 폴더명 입력\n",
        "data_dir = '/content/drive/My Drive/2021_Spring_Capstone/data/'\n",
        "\n",
        "# 테스트에 사용할 학습된 weight 파일 (.h5) 경로 입력\n",
        "weight_dir = '/content/drive/My Drive/2021_Spring_Capstone/weights/model.80-2.5578.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXAE6Si84lOz"
      },
      "source": [
        "# 테스트 결과를 저장할 폴더명 입력 - 없으면 자동으로 만드니 미리 만들어둘 필요 없음\n",
        "pred_path = base_dir + 'predicted_validation_set/'\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists(pred_path):\n",
        "    os.makedirs(pred_path)\n",
        "\n",
        "# pred_path 폴더가 만들어 졌는지 확인 후 다음 셀 진행"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L5dr9cPi8re",
        "outputId": "876966b8-d4e7-4dca-d6c0-9873f89013e6"
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "#from keras.utils import multi_gpu_model\n",
        "#from keras.utils import plot_model\n",
        "\n",
        "\n",
        "l2_reg = l2(1e-3)\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    input_tensor = Input(shape=(img_rows, img_cols, 1))\n",
        "    x = Conv2D(64, (kernel, kernel), activation='relu', padding='same', name='conv1_1',\n",
        "               kernel_initializer=\"he_normal\",kernel_regularizer=l2_reg)(input_tensor)\n",
        "    x = Conv2D(64, (kernel, kernel), activation='relu', padding='same', name='conv1_2', kernel_initializer=\"he_normal\",\n",
        "               kernel_regularizer=l2_reg, strides=(2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(128, (kernel, kernel), activation='relu', padding='same', name='conv2_1', kernel_initializer=\"he_normal\",\n",
        "               kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(128, (kernel, kernel), activation='relu', padding='same', name='conv2_2', kernel_initializer=\"he_normal\",\n",
        "               kernel_regularizer=l2_reg,\n",
        "               strides=(2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(256, (kernel, kernel), activation='relu', padding='same', name='conv3_1',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(256, (kernel, kernel), activation='relu', padding='same', name='conv3_2',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(256, (kernel, kernel), activation='relu', padding='same', name='conv3_3', kernel_initializer=\"he_normal\",\n",
        "               strides=(2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', name='conv4_1',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', name='conv4_2',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', name='conv4_3',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', dilation_rate=2, name='conv5_1',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', dilation_rate=2, name='conv5_2',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', dilation_rate=2, name='conv5_3',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', dilation_rate=2, name='conv6_1',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', dilation_rate=2, name='conv6_2',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', dilation_rate=2, name='conv6_3',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(256, (kernel, kernel), activation='relu', padding='same', name='conv7_1',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(256, (kernel, kernel), activation='relu', padding='same', name='conv7_2',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(256, (kernel, kernel), activation='relu', padding='same', name='conv7_3',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(128, (kernel, kernel), activation='relu', padding='same', name='conv8_1',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(128, (kernel, kernel), activation='relu', padding='same', name='conv8_2',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(128, (kernel, kernel), activation='relu', padding='same', name='conv8_3',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    outputs = Conv2D(num_classes, (1, 1), activation='softmax', padding='same', name='pred')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=outputs, name=\"ColorNet\")\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with tf.device(\"/gpu:0\"):\n",
        "        model = build_model()\n",
        "    print(model.summary())\n",
        "    #plot_model(encoder_decoder, to_file='encoder_decoder.svg', show_layer_names=True, show_shapes=True)\n",
        "\n",
        "    #parallel_model = multi_gpu_model(encoder_decoder, gpus=None) # 멀티 모델이 정의되지 않아 오류\n",
        "    #print(parallel_model.summary())\n",
        "    #plot_model(parallel_model, to_file='parallel_model.svg', show_layer_names=True, show_shapes=True)\n",
        "\n",
        "    K.clear_session()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ColorNet\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 256, 256, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv1_1 (Conv2D)             (None, 256, 256, 64)      640       \n",
            "_________________________________________________________________\n",
            "conv1_2 (Conv2D)             (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 128, 128, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2_1 (Conv2D)             (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2_2 (Conv2D)             (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv3_1 (Conv2D)             (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv3_2 (Conv2D)             (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv3_3 (Conv2D)             (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv4_1 (Conv2D)             (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv4_2 (Conv2D)             (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv4_3 (Conv2D)             (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv5_1 (Conv2D)             (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv5_2 (Conv2D)             (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv5_3 (Conv2D)             (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 32, 32, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv6_1 (Conv2D)             (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv6_2 (Conv2D)             (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv6_3 (Conv2D)             (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32, 32, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv7_1 (Conv2D)             (None, 32, 32, 256)       1179904   \n",
            "_________________________________________________________________\n",
            "conv7_2 (Conv2D)             (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv7_3 (Conv2D)             (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 64, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv8_1 (Conv2D)             (None, 64, 64, 128)       295040    \n",
            "_________________________________________________________________\n",
            "conv8_2 (Conv2D)             (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "conv8_3 (Conv2D)             (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "pred (Conv2D)                (None, 64, 64, 313)       40377     \n",
            "=================================================================\n",
            "Total params: 24,793,081\n",
            "Trainable params: 24,788,345\n",
            "Non-trainable params: 4,736\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pGp7aoSLk4LH",
        "outputId": "59f1e056-4112-4a1e-d505-4051ad484442"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-sLpe-Vck5Pk",
        "outputId": "d80bd152-0dfa-4afb-dbfd-4001e576b339"
      },
      "source": [
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "3bzNl2VEil3K",
        "outputId": "f760bde1-0b8b-4e00-ed72-b567c5086e79"
      },
      "source": [
        "# import the necessary packages\n",
        "import os\n",
        "import random\n",
        "#from tensorflow.keras.models import load_model\n",
        "\n",
        "import cv2 as cv\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "import sklearn.neighbors as nn\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    channel = 3\n",
        "\n",
        "    model_weights_path = weight_dir\n",
        "    model.load_weights(model_weights_path)\n",
        "\n",
        "    #print(model.summary())\n",
        "\n",
        "    image_folder = img_dir\n",
        "    names_file = base_dir + 'valid_names.txt'\n",
        "    with open(names_file, 'r') as f:\n",
        "        names = f.read().splitlines()\n",
        "\n",
        "    h, w = img_rows // 4, img_cols // 4\n",
        "\n",
        "    # Load the array of quantized ab value\n",
        "    q_ab = np.load(data_dir + 'pts_in_hull.npy')\n",
        "    nb_q = q_ab.shape[0]\n",
        "\n",
        "    # Fit a NN to q_ab\n",
        "    nn_finder = nn.NearestNeighbors(n_neighbors=nb_neighbors, algorithm='ball_tree').fit(q_ab)\n",
        "\n",
        "    for i in names:\n",
        "        image_name = i\n",
        "        filename = os.path.join(image_folder, image_name)\n",
        "        print('Start processing image: {}'.format(filename))\n",
        "        # b: 0 <=b<=255, g: 0 <=g<=255, r: 0 <=r<=255.\n",
        "        bgr = cv.imread(filename)\n",
        "        gray = cv.imread(filename, 0)\n",
        "        bgr = cv.resize(bgr, (img_rows, img_cols), cv.INTER_CUBIC)\n",
        "        gray = cv.resize(gray, (img_rows, img_cols), cv.INTER_CUBIC)\n",
        "        # L: 0 <=L<= 255, a: 42 <=a<= 226, b: 20 <=b<= 223.\n",
        "        lab = cv.cvtColor(bgr, cv.COLOR_BGR2LAB)\n",
        "        L = lab[:, :, 0]\n",
        "        a = lab[:, :, 1]\n",
        "        b = lab[:, :, 2]\n",
        "        # print('np.max(L): ' + str(np.max(L)))\n",
        "        # print('np.min(L): ' + str(np.min(L)))\n",
        "        # print('np.max(a): ' + str(np.max(a)))\n",
        "        # print('np.min(a): ' + str(np.min(a)))\n",
        "        # print('np.max(b): ' + str(np.max(b)))\n",
        "        # print('np.min(b): ' + str(np.min(b)))\n",
        "        x_test = np.empty((1, img_rows, img_cols, 1), dtype=np.float32)\n",
        "        x_test[0, :, :, 0] = gray / 255.\n",
        "\n",
        "        # L: 0 <=L<= 255, a: 42 <=a<= 226, b: 20 <=b<= 223.\n",
        "        X_colorized = model.predict(x_test)\n",
        "        X_colorized = X_colorized.reshape((h * w, nb_q))\n",
        "\n",
        "        # Reweight probas\n",
        "        X_colorized = np.exp(np.log(X_colorized + epsilon) / T)\n",
        "        X_colorized = X_colorized / np.sum(X_colorized, 1)[:, np.newaxis]\n",
        "\n",
        "        # Reweighted\n",
        "        q_a = q_ab[:, 0].reshape((1, 313))\n",
        "        q_b = q_ab[:, 1].reshape((1, 313))\n",
        "\n",
        "        X_a = np.sum(X_colorized * q_a, 1).reshape((h, w))\n",
        "        X_b = np.sum(X_colorized * q_b, 1).reshape((h, w))\n",
        "        # print('np.max(X_a): ' + str(np.max(X_a)))\n",
        "        # print('np.min(X_a): ' + str(np.min(X_a)))\n",
        "        # print('np.max(X_b): ' + str(np.max(X_b)))\n",
        "        # print('np.min(X_b): ' + str(np.min(X_b)))\n",
        "        X_a = cv.resize(X_a, (img_rows, img_cols), cv.INTER_CUBIC)\n",
        "        X_b = cv.resize(X_b, (img_rows, img_cols), cv.INTER_CUBIC)\n",
        "\n",
        "        # Before: -90 <=a<= 100, -110 <=b<= 110\n",
        "        # After: 38 <=a<= 228, 18 <=b<= 238\n",
        "        X_a = X_a + 128\n",
        "        X_b = X_b + 128\n",
        "        # print('np.max(X_a): ' + str(np.max(X_a)))\n",
        "        # print('np.min(X_a): ' + str(np.min(X_a)))\n",
        "        # print('np.max(X_b): ' + str(np.max(X_b)))\n",
        "        # print('np.min(X_b): ' + str(np.min(X_b)))\n",
        "\n",
        "        out_lab = np.zeros((img_rows, img_cols, 3), dtype=np.int32)\n",
        "        out_lab[:, :, 0] = lab[:, :, 0]\n",
        "        out_lab[:, :, 1] = X_a\n",
        "        out_lab[:, :, 2] = X_b\n",
        "        out_L = out_lab[:, :, 0]\n",
        "        out_a = out_lab[:, :, 1]\n",
        "        out_b = out_lab[:, :, 2]\n",
        "        # print('np.max(out_L): ' + str(np.max(out_L)))\n",
        "        # print('np.min(out_L): ' + str(np.min(out_L)))\n",
        "        # print('np.max(out_a): ' + str(np.max(out_a)))\n",
        "        # print('np.min(out_a): ' + str(np.min(out_a)))\n",
        "        # print('np.max(out_b): ' + str(np.max(out_b)))\n",
        "        # print('np.min(out_b): ' + str(np.min(out_b)))\n",
        "        out_lab = out_lab.astype(np.uint8)\n",
        "        out_bgr = cv.cvtColor(out_lab, cv.COLOR_LAB2BGR)\n",
        "        # print('np.max(out_bgr): ' + str(np.max(out_bgr)))\n",
        "        # print('np.min(out_bgr): ' + str(np.min(out_bgr)))\n",
        "        out_bgr = out_bgr.astype(np.uint8)\n",
        "\n",
        "        cv.imwrite(pred_path + '{}_image.png'.format(i), gray)\n",
        "        cv.imwrite(pred_path + '{}_gt.png'.format(i), bgr)\n",
        "        cv.imwrite(pred_path + '{}_out.png'.format(i), out_bgr)\n",
        "\n",
        "    K.clear_session()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start processing image: /content/drive/My Drive/2021_Spring_Capstone/test_img/00000436_(5).jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-70c32ee05948>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mbgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mbgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# L: 0 <=L<= 255, a: 42 <=a<= 226, b: 20 <=b<= 223.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLk75EU9pfd6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}